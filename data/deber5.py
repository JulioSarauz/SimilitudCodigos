# -*- coding: utf-8 -*-
"""deber5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XnZaodfhlR2UVPsn6JCaEXhO3JOWRO6t
"""

# Librerias
import csv
import re
import nltk
import numpy as np
import math
from time import time

nltk.download( 'stopwords' )

from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()

# Listas donde se guardaran los datos del csv
titulos_csv = []
palabras = []
contenido = []
STOPWORDS = stopwords.words( 'english' )
STEMMER = PorterStemmer()
 
with open( '[UCI] AAAI-14 Accepted Papers - Papers.csv', 'r', encoding='utf-8' ) as f:
        reader = csv.reader( f )
        for re in reader:
            titulos_csv.append( re[0] )
            palabras.append( re[3] )
            contenido.append( re[5] )



#print(titulos)
#print(palabras)
#print(contenido
#steming
def steaming(cont):
    strti=[]
    for i in cont:
      strti.append(STEMMER.stem(i))
    return strti
#caracteres
def caracteres(cont):
  import re
  return re.sub( '[^A-Za-z0-9]+', ' ', cont.lower() )

#stopwords
def stop(cont):
  cont2= cont
  for i in cont:
    if i in STOPWORDS:
      cont2.remove(i)
  return cont2

#limpieza de datos para titulos palabras y contenido
titulos = [ caracteres(i)for i in titulos_csv]
seprado = [i.split() for i in titulos]
steming = [steaming(i)for i in seprado]
stop_words_titulos=[stop(i)for i in steming] 
#Limpieza para palabras
palabra = [ caracteres(i)for i in palabras]
seprado = [i.split() for i in palabra]
steming = [steaming(i)for i in seprado]
stop_words_palabras=[stop(i)for i in steming] 
#limpieza para contenido
conteni = [ caracteres(i)for i in contenido]
seprado = [i.split() for i in conteni]
steming = [steaming(i)for i in seprado]
stop_words_contenido=[stop(i)for i in steming] 

##distancia de jaccard para lso titulos
def jaccard(titulos, valor):
  distancia=np.zeros( (len( titulos ), len( titulos )), dtype=float )
  valor=0
  for i in titulos:
    valor2=0
    for j in titulos:
      interseccion = len( np.intersect1d( i, j ))
      union = len( np.union1d( i, j ))
      total = (interseccion / union)* valor
      distancia[valor][valor2]= total
      valor2+=1
    valor+=1
  return distancia


jaccard_titulos=jaccard(stop_words_titulos,0.1)
print("***Distancias de jaccard*****")
print(jaccard_titulos)

print("********Distancia de jaccard para palabras clave ********")
jaccard_palabras_clave=jaccard(stop_words_palabras,0.3)
print(jaccard_palabras_clave)

#coseno de distancias
def coseno_distancias(abstract, peso):
  coseno=np.zeros( (len( abstract ), len( abstract )), dtype=float )
  valor=0
  for i in abstract:
    valor2=0
    for j in abstract:
      total = 0
      for x, l in zip( i, j ):
          total += (x * l)
          total = total * peso
      coseno[valor][valor2]=total
      valor2+=1
    valor+=1
  return coseno
#bolsa de palabras
contenido2 = []
bolsa= []
for i in stop_words_contenido:
  contenido2.append( ' '.join( i ) )
x = vectorizer.fit_transform( contenido2 )
for i in x.toarray():
  bolsa.append( list( i ) )

#pesado
pesado= []
for i in bolsa:
  aux= []
  for j in i:
    if j > 0:
     aux.append( 1 + math.log10( j ) )
    else:
      aux.append( 0 )
  pesado.append(aux)
#Frecuencia 
frecuencia=[0] * len( pesado[0] )
for i in pesado:
  poss=0
  for j in i :
    if j>0:
      frecuencia[poss]+=1
    poss+=1
#idf
peso=0.7 #para contenido
idf = []
n = len( pesado )
for i in frecuencia:
  idf.append( math.log10( n / i ) )

#tf_idf
tf_idf = []
for i in pesado:
  valor = []
  for j, k in zip( i, idf ):
    valor.append( j * k )
  tf_idf.append( valor )

#normalizacion
final = []
for i in tf_idf:
  normal =[]
  aux = 0
  for j in i:
    aux = aux + j ** 2
  aux = math.sqrt( aux )
  for k in i:
    normal.append( k / aux )
  final.append( normal )

#impresion del cose de los contenidos

dist_contenidos = coseno_distancias(final,peso)
print("***********Distancia de coseno con contenidosss*********")
print(dist_contenidos)
#para el coseno se necesita sacar el pesado




#arrancamos nuestras funciones